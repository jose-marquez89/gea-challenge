{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model: Aggregated Probability\n",
    "After trying several approaches in the sandbox notebooks, I settled on \n",
    "the following approach given a time constraint: The aggregated probabilities\n",
    "of a nearest neighbors classifier on sequence permutations (TFIDF scores) and \n",
    "and a random forest classifier on the one-hot encoded portion of the training \n",
    "data. The following is a distillation of the best scoring process in the sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import permutations\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing The Data\n",
    "Before being able to fit any models, some feature engineering needs to be performed on the training observations, and the training labels need to be collapsed down to a usable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.read_csv(\"train_values.csv\")\n",
    "labels = pd.read_csv(\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>lab_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ZIMC</td>\n",
       "      <td>RYUA3GVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5SAQC</td>\n",
       "      <td>RYUA3GVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E7QRO</td>\n",
       "      <td>RYUA3GVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CT5FP</td>\n",
       "      <td>RYUA3GVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7PTD8</td>\n",
       "      <td>RYUA3GVO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id    lab_id\n",
       "0       9ZIMC  RYUA3GVO\n",
       "1       5SAQC  RYUA3GVO\n",
       "2       E7QRO  RYUA3GVO\n",
       "3       CT5FP  RYUA3GVO\n",
       "4       7PTD8  RYUA3GVO"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the main label series\n",
    "\n",
    "lab_ids = labels.columns[1:]\n",
    "\n",
    "# get numpy matrix of lab_id one-hot values\n",
    "lab_matrix = labels.drop(columns=['sequence_id']).values\n",
    "\n",
    "# get array of indices to map back to lab_ids\n",
    "lab_col_indices = np.asarray(lab_matrix == 1).nonzero()[1]\n",
    "\n",
    "labels['lab_id'] = lab_ids[lab_col_indices]\n",
    "y = labels[['sequence_id', 'lab_id']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that all labels are correct\n",
    "def correct_label(row_n):\n",
    "    return labels.iloc[row_n][labels['lab_id'].iloc[row_n]] == 1\n",
    "\n",
    "assert all(list(map(correct_label, range(labels.shape[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to effectively use RandomizedSearchCV, some of the observations where classes had very few members needed to be \n",
    "oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMOD7PGG    4\n",
      "8N5EPD5C    4\n",
      "YCD71LRY    4\n",
      "68OY1RK5    4\n",
      "PXT3AJ7C    4\n",
      "03GRNN7N    4\n",
      "VDSDXJ71    4\n",
      "INDCDVP0    4\n",
      "W2DYAZID    4\n",
      "1KZHNVYR    4\n",
      "LGTP4O86    4\n",
      "RZPGGEG4    4\n",
      "XCWSW5T9    4\n",
      "WM3Q8LBC    4\n",
      "58BSUZQB    3\n",
      "G2P73NZ0    3\n",
      "WB78G3XF    2\n",
      "0L3Y6ZB2    1\n",
      "ON9AXMKF    1\n",
      "Name: lab_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# these are the classes with less than 5 members\n",
    "# need all to have at least 5 for randomized search cv\n",
    "print(y['lab_id'].value_counts().tail(19))\n",
    "\n",
    "# create resampling map\n",
    "resample_map = y['lab_id'].value_counts().tail(19)\n",
    "resample_map = list(zip(resample_map.index, resample_map.values))\n",
    "\n",
    "# temporarily add 'lab_id' back to\n",
    "over_samp = pd.concat([values, y['lab_id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(df, resamp_map, min_samps=5):\n",
    "    \"\"\"\n",
    "    Randomly oversample rows that belong to classes with less than N\n",
    "    members\n",
    "    \n",
    "    df: pandas DataFrame object\n",
    "    resamp_map: reference values for classes and resample amount\n",
    "    \"\"\"\n",
    "    new_df = df.copy()\n",
    "    for class_, members in resamp_map:\n",
    "        for i in range(min_samps - members):\n",
    "            new_row = new_df.loc[new_df['lab_id'] == class_].sample(n=1)\n",
    "            new_df = new_df.append(new_row)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each class has a minimum of 5 members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VDSDXJ71    5\n",
       "8F0XPAZX    5\n",
       "DN01XVIU    5\n",
       "HCW1Y9QM    5\n",
       "I3UODLOR    5\n",
       "5Z4CMIY5    5\n",
       "QNKGHIRB    5\n",
       "W2DYAZID    5\n",
       "78XDAJNS    5\n",
       "G6MP6EIN    5\n",
       "LGTP4O86    5\n",
       "E59C5N01    5\n",
       "78QGAL01    5\n",
       "RZPGGEG4    5\n",
       "XCWSW5T9    5\n",
       "5CBNCRST    5\n",
       "03GRNN7N    5\n",
       "VMU0L6UM    5\n",
       "XYB5NWR4    5\n",
       "NDZT8PV3    5\n",
       "Name: lab_id, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_samp = oversample(over_samp, resample_map)\n",
    "over_samp['lab_id'].value_counts().tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is oversampled for use with RandomizedSearchCV, a function can be created that will take train and test data, and output the appropriate data set for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TGNC', 'TGNA', 'TGCN', 'TGCA', 'TGAN']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, ngrams for sequences must be made\n",
    "N_GRAMS = 4\n",
    "\n",
    "# create the 'vocabulary' for the different nucleotides\n",
    "n_tides = set(''.join(over_samp['sequence'].values))\n",
    "\n",
    "# create a list of subsequences for features\n",
    "subseqs = list(''.join(p) for p in permutations(n_tides, r=N_GRAMS))\n",
    "subseqs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(data, sequences):\n",
    "    \"\"\"\n",
    "    Splits train or testing data into one-hot\n",
    "    encoded data and tokenized sequences\n",
    "    \"\"\"\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data-gov)",
   "language": "python",
   "name": "data-gov"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
